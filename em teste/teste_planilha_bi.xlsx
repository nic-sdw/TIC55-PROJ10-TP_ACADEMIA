import os
import requests
import pandas as pd
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

# --- CONFIGURA√á√ïES PACTO ---
TOKEN = os.getenv("TOKEN")
EMPRESA_ID = os.getenv("EMPRESA_ID")
URL_BASE = "https://apigw.pactosolucoes.com.br"

headers = {
    "Authorization": f"Bearer {TOKEN}",
    "empresaId": EMPRESA_ID,
    "Content-Type": "application/json"
}

def fetch_pacto_data(path, params):
    url = f"{URL_BASE}{path}"
    time.sleep(1.3)
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        return response.json() if response.status_code == 200 else None
    except Exception as e:
        print(f"Erro na API: {e}")
        return None

def processar_dados_bi(df_bruto, dias_filtro):
    print(f"--- Processando Dados (√öltimos {dias_filtro} dias) ---")
    
    # Mapeamento ZW que validamos antes
    mapeamento = {
        'matriculaZW': 'MATRICULA',
        'nome': 'ALUNO',
        'sexo': 'SEXO',
        'dataNascimento': 'NASCIMENTO',
        'situacaoAluno': 'STATUS',
        'dataMatriculaZW': 'DATA_ADESAO'
    }
    
    df = df_bruto.rename(columns=mapeamento).copy()

    # Tratamento de Datas
    df['DATA_ADESAO'] = pd.to_datetime(df['DATA_ADESAO'], errors='coerce')
    data_limite = datetime.now() - timedelta(days=dias_filtro)
    df = df[df['DATA_ADESAO'] >= data_limite].copy()

    if df.empty:
        return pd.DataFrame()

    # C√°lculo de Idade
    df['NASCIMENTO'] = pd.to_datetime(df['NASCIMENTO'], errors='coerce')
    ano_atual = datetime.now().year
    df['IDADE'] = ano_atual - df['NASCIMENTO'].dt.year
    
    # Categoriza√ß√£o de Faixa Et√°ria
    bins = [0, 18, 25, 35, 45, 60, 120]
    labels = ['0-17', '18-25', '26-35', '36-45', '46-60', '60+']
    df['FAIXA_ETARIA'] = pd.cut(df['IDADE'], bins=bins, labels=labels)

    # Limpeza de Sexo e Status de Desist√™ncia
    df['SEXO'] = df['SEXO'].astype(str).str.title()
    status_ativos = ['Ativo', 'Vigente', 'Aguardando In√≠cio']
    df['DESISTENTE'] = df['STATUS'].apply(lambda x: 'N√£o' if x in status_ativos else 'Sim')

    return df

def gerar_planilha_local(df):
    """Gera um arquivo Excel id√™ntico ao que ir√° para o Google Sheets"""
    print("\n--- üìÇ GERANDO PLANILHA LOCAL DE TESTE ---")
    
    nome_arquivo = "teste_planilha_bi.xlsx"
    
    # Sele√ß√£o de colunas para o Looker
    cols_bi = ['MATRICULA', 'ALUNO', 'SEXO', 'IDADE', 'FAIXA_ETARIA', 'STATUS', 'DESISTENTE', 'DATA_ADESAO']
    df_final = df[[c for c in cols_bi if c in df.columns]].copy()
    
    # Formatando a data para ficar bonita no Excel
    df_final['DATA_ADESAO'] = df_final['DATA_ADESAO'].dt.strftime('%d/%m/%Y')
    
    # Salva em Excel (Requer 'pip install openpyxl')
    try:
        df_final.to_excel(nome_arquivo, index=False, sheet_name='Dados_BI')
        print(f"‚úÖ SUCESSO! Abra o arquivo '{nome_arquivo}' para validar os dados.")
    except Exception as e:
        print(f"‚ùå Erro ao gerar Excel: {e}. Gerando CSV como fallback...")
        df_final.to_csv("teste_planilha_bi.csv", index=False, sep=';', encoding='utf-8-sig')

if __name__ == "__main__":
    print("--- üöÄ INICIANDO EXTRA√á√ÉO DE TESTE ---")
    path = "/psec/alunos/v2"
    lista_acumulada = []
    
    # Vamos pegar 3 p√°ginas (300 registros) para o teste ser r√°pido
    for p in range(3):
        params = {"page": p, "size": 100}
        dados = fetch_pacto_data(path, params)
        if not dados: break
        content = dados.get('content', [])
        if not content: break
        lista_acumulada.extend(content)
        print(f"   > Coletando p√°gina {p}...")

    if lista_acumulada:
        df_raw = pd.DataFrame(lista_acumulada)
        df_processado = processar_dados_bi(df_raw, 30)

        if not df_processado.empty:
            gerar_planilha_local(df_processado)
        else:
            print("‚ö†Ô∏è Nenhum aluno encontrado nos √∫ltimos 30 dias nestas p√°ginas.")
    else:
        print("‚ùå Falha ao conectar com a Pacto.")